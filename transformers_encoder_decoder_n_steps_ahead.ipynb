{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Some of the implementation of the full transformer architecture was adapted from the imperial NLP course\n",
    "# https://github.com/ImperialNLP/NLPLabs-2022/tree/main/transformers_code_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, defaultdict\n",
    "import math\n",
    "import yfinance as yf\n",
    "import os\n",
    "from pytorch_lightning import seed_everything\n",
    "import random\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1233)\n",
    "torch.manual_seed(1233)\n",
    "np.random.seed(1233)\n",
    "seed_everything(1233, workers=True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.3, max_seq_len=200, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model).to(device)\n",
    "        pos = torch.arange(0, max_seq_len).unsqueeze(1).float()\n",
    "\n",
    "        two_i = torch.arange(0, d_model, step=2).float()\n",
    "        div_term = torch.pow(10000, (two_i/torch.Tensor([d_model]))).float()\n",
    "        pe[:, 0::2] = torch.sin(pos/div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos/div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape(x) = [B x seq_len x D]\n",
    "        pe = self.pe[:, :x.shape[1]].detach()\n",
    "        x = x.add(pe)\n",
    "        # shape(x) = [B x seq_len x D]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2VecPositonalEncoding(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, activation=\"sine\"):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(input_dim, 1)\n",
    "        self.periodic_layer = nn.Linear(input_dim, output_dim - 1)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.activation == \"sine\":\n",
    "            periodic_out = torch.sin(self.periodic_layer(x))\n",
    "        elif self.activation == \"cos\":\n",
    "            periodic_out = torch.cos(self.periodic_layer(x))\n",
    "\n",
    "        \n",
    "        original_out = self.linear_layer(x)\n",
    "\n",
    "        out = torch.cat([periodic_out, original_out], 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # print(config)\n",
    "        dropout = config[\"dropout\"]\n",
    "        device = config[\"device\"]\n",
    "        max_seq_len = config[\"max_seq_len\"]\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        input_dim, d_model = config[\"input_dim\"], config[\"d_model\"]\n",
    "        self.inputProjection = nn.Linear(input_dim, d_model)\n",
    "        self.targetProjection = nn.Linear(input_dim, d_model)\n",
    "\n",
    "\n",
    "        n_head, num_enc_layers, num_dec_layers = config[\"n_head\"], config[\"num_enc_layers\"], config[\"num_dec_layers\"] \n",
    "        self.transformer = nn.Transformer(d_model, n_head, num_enc_layers, num_dec_layers, \n",
    "            dim_feedforward= 4 * d_model, dropout=dropout, batch_first=True, device=device)\n",
    "        \n",
    "        self.encoderLayer = nn.TransformerEncoderLayer(d_model, n_head, dim_feedforward=4 * d_model, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoderLayer, num_enc_layers)\n",
    "\n",
    "        steps_ahead = config[\"steps_ahead\"]\n",
    "        self.linear = nn.Linear(d_model, 1)\n",
    "        self.decoder = nn.Linear(d_model * steps_ahead, steps_ahead)\n",
    "        self.d_model = d_model\n",
    "        self.use_encoder_only = config[\"use_encoder_only\"]\n",
    "        self.useInputProjection = config[\"use_input_projections\"]\n",
    "\n",
    "        self.isClassification = config[\"is_classification\"] \n",
    "         \n",
    "\n",
    "        if config[\"use_absolute_enc\"]:\n",
    "            self.inputPosEncoding = AbsolutePositionalEncoding(d_model, dropout, max_seq_len, device)\n",
    "            self.outputPosEncoding = AbsolutePositionalEncoding(d_model, dropout, max_seq_len, device)\n",
    "        else:\n",
    "            time2vecActivation = config[\"activation\"]\n",
    "            self.inputPosEncoding = Time2VecPositonalEncoding(input_dim, d_model, time2vecActivation)\n",
    "            self.outputPosEncoding = Time2VecPositonalEncoding(input_dim, d_model, time2vecActivation)\n",
    "    \n",
    "    \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        \n",
    "    def create_mask(self, size):\n",
    "        return torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.create_mask(src.shape[1])\n",
    "        src_mask = src_mask.type_as(src)\n",
    "        trg_mask = self.create_mask(trg.shape[1])\n",
    "        trg_mask = trg_mask.type_as(trg)\n",
    "        \n",
    "        if self.useInputProjection:\n",
    "            src = self.inputProjection(src)\n",
    "            trg = self.targetProjection(trg)\n",
    "\n",
    "        if self.use_encoder_only:\n",
    "            src = self.inputPosEncoding(src)\n",
    "            out = self.encoder(src, src_mask)\n",
    "            out = self.linear(out)\n",
    "            if self.isClassification:\n",
    "                out = F.log_softmax(out)\n",
    "            return out\n",
    "        else:\n",
    "            src = self.inputPosEncoding(src)\n",
    "            trg = self.outputPosEncoding(trg) \n",
    " \n",
    "            out = self.transformer(src, trg, tgt_mask=trg_mask)\n",
    "            out = self.linear(out)\n",
    "            # out = self.decoder(out.flatten(start_dim=1))\n",
    "            if self.isClassification:\n",
    "                out = F.log_softmax(out)\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_loss(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def get_prediction(t):\n",
    "    return [arr.view(-1) for arr in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTrainer(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        config[\"device\"] = self.hparams.config['device']\n",
    "        self.model = TimeSeriesTransformer(config)\n",
    "\n",
    "        self.d_model= config[\"d_model\"]\n",
    "        self.warmup_steps = config[\"warmup_steps\"]\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.device_ = self.hparams.config['device']\n",
    "        self.config = config\n",
    "        self.training_len = config[\"training_len\"]\n",
    "        self.sampling = config[\"sampling\"]\n",
    "        self.forecast_window = config[\"steps_ahead\"]\n",
    "        self.k = config[\"k\"]\n",
    "        self.threshold = config[\"threshold\"]\n",
    "\n",
    "        if config[\"loss\"] == 'mse':\n",
    "            self.criterion = nn.MSELoss(reduction='sum')\n",
    "        else:\n",
    "            self.criterion = r2_loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def change_lr_in_optimizer(self):\n",
    "        min_arg1 = math.sqrt(self.global_step)\n",
    "        min_arg2 = self.global_step * (self.warmup_steps**-1.5)\n",
    "        lr = math.sqrt(self.d_model) * min(min_arg1, min_arg2)\n",
    "        self.trainer.lightning_optimizers[0].param_groups[0]['lr'] = lr\n",
    "    \n",
    "    def prob_get_true_val(self, p):\n",
    "        return random.random() < p\n",
    "\n",
    "    def n_step_forward(self, src, trg):\n",
    "        sampled_input = src\n",
    "        all_preds = [] \n",
    "\n",
    "        # src.shape: [64, 60, 1]\n",
    "        # tgt_in.shape: [64, 30, 1]\n",
    "        # tgt_out: [64, 30]\n",
    "\n",
    "        for i in range(self.forecast_window):\n",
    "           \n",
    "            pred = self.model(sampled_input, trg[:, i, :].unsqueeze(-1))\n",
    "            ## pred shape: [B * 1 * 1]\n",
    "\n",
    "            if all_preds == []:\n",
    "                all_preds = pred\n",
    "            else:\n",
    "                all_preds = torch.cat((all_preds, pred), dim=1)\n",
    "\n",
    "            p = self.k / (self.k + math.exp(self.current_epoch/self.k))\n",
    "\n",
    "            prob_true_val = True\n",
    "            if self.sampling and i > self.threshold:\n",
    "                prob_true_val = self.prob_get_true_val(p)\n",
    "            \n",
    "            if prob_true_val and i > self.threshold:\n",
    "                sampled_input = torch.cat((sampled_input[:, 1:, :].detach(), trg[:, i, :].unsqueeze(-1).detach()), dim=1)\n",
    "            else:\n",
    "                sampled_input = torch.cat((sampled_input[:, 1:, :].detach(), pred.detach()), dim=1)\n",
    "            \n",
    "        return all_preds\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, trg_in, targets = batch\n",
    "\n",
    "        y_hat = self.n_step_forward(src, trg_in)\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        y = targets\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        pearson_corr = self.calc_pearson_coeff(y_hat, y)\n",
    "\n",
    "        self.log(\"train_pearson_coef\", pearson_corr ,on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.change_lr_in_optimizer()\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs): \n",
    "        avg_loss = torch.stack(\n",
    "            [x[\"loss\"].detach() for x in outputs]).mean()\n",
    "\n",
    "        if self.current_epoch % 5 == 0:\n",
    "            self.print_predictions(train_loader_unshuffled, train_output_img_dir+\"train\", \"Training\")\n",
    "        \n",
    "        self.log_dict({\"train_loss_epoch\": avg_loss, \"step\":self.current_epoch})\n",
    "\n",
    "    \n",
    "    def print_predictions(self, dataloader, file_prefix, title=\"Validation\"):\n",
    "        # print predictiion of first 1024 + 100 data points\n",
    "        with torch.no_grad():\n",
    "            all_predictions = []\n",
    "            init_train_data = []\n",
    "            all_targets = []\n",
    "            for step, trng_data in enumerate(dataloader):\n",
    "                if step == 1:\n",
    "                    break\n",
    "\n",
    "                src, _, targets = trng_data\n",
    "                all_targets.append(targets[0].detach().cpu())\n",
    "\n",
    "                if step == 0:\n",
    "                    init_train_data = src[0, :, 0].reshape(-1)\n",
    "\n",
    "                prediction = self(trng_data)\n",
    "                all_predictions.append(prediction[0].detach().cpu())\n",
    "\n",
    "          \n",
    "            all_predictions = flatten(get_prediction(all_predictions))\n",
    "            all_predictions = np.array(all_predictions)\n",
    "            all_targets = flatten(get_prediction(all_targets))\n",
    "            all_targets = np.array(all_targets)\n",
    "\n",
    "            # print(all_predictions.shape)\n",
    "            # print(all_targets.shape)\n",
    "            # print(init_train_data.shape)\n",
    "\n",
    "            # inverse transform\n",
    "            init_train_data = train_targets_scaler.inverse_transform(init_train_data.reshape(-1, 1)).reshape(-1)\n",
    "            all_predictions = train_targets_scaler.inverse_transform(all_predictions.reshape(-1, 1)).reshape(-1)\n",
    "            all_targets = train_targets_scaler.inverse_transform(all_targets.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "            end_plot_idx = self.training_len + len(all_predictions)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(init_train_data, label='trailing')\n",
    "            plt.plot(np.arange(self.training_len, end_plot_idx), all_predictions, label=\"predicted\")\n",
    "            plt.plot(np.arange(self.training_len, end_plot_idx), all_targets, label=\"actual\")\n",
    "            plt.title(f\"{title} prediction for epoch {self.current_epoch}\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "\n",
    "            if not os.path.exists(file_prefix):\n",
    "                os.makedirs(file_prefix)\n",
    "\n",
    "            plt.savefig(f\"{file_prefix}/Next_{len(all_predictions)}_preds_Epoch_{self.current_epoch}.jpg\", bbox_inches=\"tight\")\n",
    "            \n",
    "            plt.close()\n",
    "            # plt.show()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg_in, targets = batch\n",
    "\n",
    "        y_hat = self.n_step_forward(src, trg_in)\n",
    "        y_hat = y_hat.squeeze(-1)\n",
    "        y = targets\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        self.log(\"valid_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        pearson_corr = self.calc_pearson_coeff(y_hat, y)\n",
    "\n",
    "        self.log(\"val_pearson_coef\", pearson_corr ,on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss \n",
    "    \n",
    "\n",
    "    def calc_pearson_coeff(self, y_pred, y):\n",
    "\n",
    "        predicted = y_pred\n",
    "        targets = y\n",
    "        vy_pred = predicted - torch.mean(predicted)\n",
    "        vy = targets - torch.mean(targets)\n",
    "        denom = torch.sum(vy_pred ** 2) * torch.sum(vy ** 2)\n",
    "\n",
    "        corr = torch.sum(vy_pred * vy) / torch.sqrt(denom)\n",
    "\n",
    "        return corr\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack(\n",
    "            [x.detach() for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"ptl/val_loss\", avg_loss)\n",
    "\n",
    "        if self.current_epoch % 5 == 0:\n",
    "            self.print_predictions(val_loader, train_output_img_dir+\"val\")\n",
    "        \n",
    "        self.log_dict({\"valid_loss_epoch\": avg_loss, \"step\":self.current_epoch})\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        src, trg_in, _ = x\n",
    "        src = src.to(self._device)\n",
    "        trg_in = trg_in.to(self._device)\n",
    "        return self.n_step_forward(src, trg_in)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sequence Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_multiplier = 1_000_000\n",
    "f_multiplier = 1\n",
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, features, targets, training_len, forecast_len):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.training_len = training_len\n",
    "        self.forecast_len = forecast_len\n",
    "        self.feature_len = len(features)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.feature_len - self.training_len - self.forecast_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        end_trng_idx = idx + self.training_len\n",
    "        end_target_idx = end_trng_idx + self.forecast_len\n",
    "\n",
    "        train_features = torch.as_tensor(f_multiplier * self.features[idx:end_trng_idx], dtype=torch.float32)\n",
    "        # first output to decoder is last input to encoder\n",
    "        target_features = torch.as_tensor(f_multiplier * self.features[end_trng_idx - 1:end_target_idx - 1], dtype=torch.float32)\n",
    "        target_values = torch.as_tensor(self.targets[end_trng_idx:end_target_idx], dtype=torch.float32)\n",
    " \n",
    "        return FeaturesAndTarget(train_features, target_features, target_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(codes, start_date, end_date):\n",
    "    data = yf.download(codes, start_date, end_date)\n",
    "\n",
    "    if len(codes) == 1:\n",
    "        data.columns = [data.columns, codes*len(data.columns)]\n",
    "\n",
    "    return data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"^GSPC\", \"AAPL\", \"MSFT\", \"NKE\", \"JPM\" , \"JNJ\"]\n",
    "ticker = \"MSFT\"\n",
    "daily_data = download_data(tickers, \"2018-05-01\", \"2022-05-01\")\n",
    "close_data = daily_data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_data = close_data[ticker].values\n",
    "prices_data = prices_data.reshape(-1)\n",
    "\n",
    "plt.plot(prices_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prices_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(prices_data):\n",
    "\n",
    "    features = pd.DataFrame(dict(px=prices_data)).assign(\n",
    "        dpx1 = lambda x: x.px.ewm(span=8).mean() - x.px.ewm(span=32).mean(),\n",
    "        dpx2 = lambda x: x.px.ewm(span=32).mean() - x.px.ewm(span=64).mean(),\n",
    "        dpx3 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "        dpx4 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "        dpx5 = lambda x: x.px.ewm(12).mean() - x.px.ewm(26).mean(),\n",
    "        # dpx1 = lambda x: x.px.ewm(20).mean(),\n",
    "        # dpx2 = lambda x: x.px.ewm(50).mean(),\n",
    "        # dpx3 = lambda x: x.px.ewm(100).mean(),\n",
    "        # adj_close_diff_1 = lambda x: x.px.diff(),\n",
    "        # adj_close_pct_diff = lambda x: x.px.pct_change(),\n",
    "        # dpx1 = lambda x: np.diff(x.px, prepend=x.px[0]),\n",
    "        # dpx2 = lambda x: np.diff(x.px, n=2, prepend=[x.px[0], x.px[0]]),\n",
    "        # dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean(), \n",
    "    )\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = create_features(prices_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesAndTarget = namedtuple('FeaturesAndTarget', ['train_features', 'target_features', 'target_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features):\n",
    "    train_idx = int(features.shape[0]*0.6)\n",
    "    val_idx = int(features.shape[0] * 0.2)\n",
    "    train_features = features[:train_idx]\n",
    "    val_features = features[train_idx:train_idx + val_idx]\n",
    "    test_features = features[train_idx + val_idx:]\n",
    "\n",
    "    return train_features, val_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, test_features = split_data(features)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    training_len=60,\n",
    "    val_len=60,\n",
    "    max_seq_len=1000,\n",
    "    batch_size=64,\n",
    "    d_model=128,\n",
    "    lr = 1e-3,\n",
    "    steps_ahead=30, \n",
    "    input_dim=1, \n",
    "    n_head=8,  \n",
    "    num_enc_layers=3,\n",
    "    num_dec_layers=3,\n",
    "   \n",
    "    dropout=0.1,\n",
    "    use_encoder_only=False, \n",
    "    use_absolute_enc=True, \n",
    "    use_input_projections=True, \n",
    "    is_classification=False, \n",
    "    device=device, \n",
    "    warmup_steps=6000,\n",
    "    loss='mse',\n",
    "    scale=True,\n",
    "    activation=\"sine\",\n",
    "    k = 60,\n",
    "\n",
    "    prices_only = True,\n",
    "    sampling =False,\n",
    "    threshold=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_features_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_targets_scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_features, val_features, test_features):\n",
    "\n",
    "    train_ema = train_features.filter(like='dpx').values\n",
    "    val_ema = val_features.filter(like='dpx').values\n",
    "    test_ema = test_features.filter(like='dpx').values\n",
    "\n",
    "    train_px = train_features['px'].values\n",
    "    val_px = val_features['px'].values\n",
    "    test_px = test_features['px'].values\n",
    "     \n",
    "\n",
    "    if params['scale']:\n",
    "        train_features_scaler.fit(train_ema)\n",
    "        train_targets_scaler.fit(train_px.reshape(-1, 1))\n",
    "\n",
    "    \n",
    "    if params['scale']:\n",
    "        f_train_ema = train_features_scaler.transform(train_ema)\n",
    "        f_val_ema = train_features_scaler.transform(val_ema)\n",
    "        f_test_ema = train_features_scaler.transform(test_ema)\n",
    "        f_train_px = train_targets_scaler.transform(train_px.reshape(-1, 1))\n",
    "        f_val_px = train_targets_scaler.transform(val_px.reshape(-1, 1))\n",
    "        f_test_px = train_targets_scaler.transform(test_px.reshape(-1, 1))\n",
    "\n",
    "        f_train_values = np.concatenate([f_train_px, f_train_ema], axis=1)\n",
    "        f_val_values = np.concatenate([f_val_px, f_val_ema], axis=1)\n",
    "        f_test_values = np.concatenate([f_test_px, f_test_ema], axis=1)\n",
    "\n",
    "    # price only data\n",
    "    if params[\"prices_only\"]:\n",
    "        f_train_values = f_train_values[:, 0].reshape(-1, 1)\n",
    "        f_val_values = f_val_values[:, 0].reshape(-1, 1)\n",
    "        f_test_values = f_test_values[:, 0].reshape(-1, 1)\n",
    "\n",
    "        f_train_targets = f_train_values.reshape(-1)\n",
    "        f_val_targets = f_val_values.reshape(-1)\n",
    "        f_test_targets = f_test_values.reshape(-1) \n",
    "    \n",
    "    else:\n",
    "        # all values, incl price\n",
    "\n",
    "        f_train_targets = f_train_values[:, 0].reshape(-1)\n",
    "        f_val_targets = f_val_values[:, 0].reshape(-1)\n",
    "        f_test_targets = f_test_values[:, 0].reshape(-1)\n",
    "    \n",
    "\n",
    "    return f_train_values, f_val_values, f_test_values, f_train_targets, f_val_targets, f_test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_values, f_val_values, f_test_values, f_train_targets, f_val_targets, f_test_targets = preprocess_data(train_features, val_features, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_len = params['training_len']\n",
    "forecast_len = params['steps_ahead']\n",
    "\n",
    "print(training_len)\n",
    "print(forecast_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(1233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = FeaturesDataset(f_train_values, f_train_targets, params['training_len'], forecast_len)\n",
    "val_dataset = FeaturesDataset(f_val_values, f_val_targets, params['val_len'], forecast_len)\n",
    "test_dataset = FeaturesDataset(f_test_values, f_test_targets, params['val_len'], forecast_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8, worker_init_fn=seed_worker, generator=gen)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "train_loader_unshuffled = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg_in, trg_out = next(iter(train_loader))\n",
    "print(src.shape)\n",
    "print(trg_in.shape)\n",
    "print(trg_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"transformer_n_step_ahead_logs\"\n",
    "model_dir = \"transformer_n_step_ahead_models\"\n",
    "\n",
    "device = (\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def train(ticker, version_name='', model_name ='', ckpt_dir='w2v'):\n",
    "\n",
    "    if version_name == '':\n",
    "        version_name = ticker\n",
    "\n",
    "    if model_name == '':\n",
    "        model_name = ticker \n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=log_dir, \n",
    "        version=f'{version_name}_{ckpt_dir}'\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"valid_loss_epoch\",\n",
    "        mode=\"min\",\n",
    "        dirpath=f\"{model_dir}/{ckpt_dir}/{model_name}\",\n",
    "        filename=\"{epoch}-{valid_loss_epoch:.4f}\",\n",
    "        save_last= True,\n",
    "        save_top_k=2\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"valid_loss_epoch\",\n",
    "        mode=\"min\",\n",
    "        patience=100\n",
    "    )\n",
    "\n",
    "    metrics = {\"loss\": \"ptl/val_loss\"}\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=200,\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        log_every_n_steps=7,\n",
    "    )\n",
    "\n",
    "    stock_model = TransformerTrainer(params)\n",
    "\n",
    "    trainer.fit(stock_model, train_loader, val_loader)\n",
    "\n",
    "    return trainer, stock_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_prediction(preds, n=0):\n",
    "    return preds[n]\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return np.concatenate(preds, axis=0)\n",
    "\n",
    "def revert_transform(values):\n",
    "    return train_targets_scaler.inverse_transform(values.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "def get_prediction_value(preds):\n",
    "    return [x.cpu().detach().numpy() for x in preds]\n",
    "\n",
    "def forecast(stock_model, trainer, ckpt_path, test_loader, nth_pred):\n",
    "    with torch.no_grad():\n",
    "        predictions = trainer.predict(dataloaders=test_loader, model=stock_model, ckpt_path=ckpt_path)\n",
    "\n",
    "    all_predictions = concat_preds(predictions)\n",
    "    predictions_flattened = np.array(flatten(get_nth_prediction(all_predictions, nth_pred)))\n",
    "    \n",
    "    return predictions_flattened\n",
    "\n",
    "def evaluate(pred, y):\n",
    "    pred = revert_transform(pred)\n",
    "    y = revert_transform(y)\n",
    "    \n",
    "    rmse = calculate_rmse(y, pred)\n",
    "    mse = rmse ** 2\n",
    "    mape = calculate_mape(y, pred)\n",
    "\n",
    "    r = calc_pearson_coeff(pred, y)\n",
    "\n",
    "    res = dict(\n",
    "        rmse = rmse,\n",
    "        mse =mse,\n",
    "        mape =mape,\n",
    "        r = r\n",
    "    )\n",
    "\n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, target, reduction='sum'):\n",
    "    loss = np.sum(np.square(pred - target))\n",
    "    if reduction == \"sum\":\n",
    "        return loss\n",
    "    else:\n",
    "        return loss / len(pred)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "\n",
    "    rmse = np.sqrt(np.mean((y_true-y_pred)**2))                   \n",
    "    return rmse\n",
    "\n",
    "def calculate_mape(y_true, y_pred): \n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)    \n",
    "    mape = np.mean(np.abs((y_true-y_pred) / y_true))*100    \n",
    "    return mape\n",
    "\n",
    "\n",
    "def calc_pearson_coeff(y_pred, y):\n",
    "\n",
    "    predicted = y_pred\n",
    "    targets = y\n",
    "    vy_pred = predicted - np.mean(predicted)\n",
    "    vy = targets - np.mean(targets)\n",
    "    denom = np.sum(vy_pred ** 2) * np.sum(vy ** 2)\n",
    "\n",
    "    corr = np.sum(vy_pred * vy) / np.sqrt(denom)\n",
    "\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = False\n",
    "img_folder = \"output_imgs/transformer_n_step/w2v/prices/\"\n",
    "\n",
    "def gen_fig(preds, eval_res, targets, img_folder, title, i = 0, savefig=False):\n",
    "    if not os.path.exists(img_folder):\n",
    "        os.makedirs(img_folder)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    start_idx = training_len + i\n",
    "    end_idx = training_len + len(preds) + i\n",
    "\n",
    "    filename = f\"{img_folder}{ticker}_results.txt\" \n",
    "    if savefig:\n",
    "        if os.path.exists(filename):\n",
    "            f = open(filename, \"a\")\n",
    "            f.write(\"\\n\")\n",
    "        else:\n",
    "            f = open(filename, \"x\")\n",
    "\n",
    "    for metric in eval_res.keys():\n",
    "        print(f\"Metric {metric}: {eval_res[metric]}\")\n",
    "        if savefig:\n",
    "            f.write(f\"Metric {metric}: {eval_res[metric]}\\n\")\n",
    "\n",
    "    plt.plot(list(range(start_idx, end_idx)), revert_transform(preds), label=\"predicted\")\n",
    "    plt.plot(list(range(start_idx, end_idx)), revert_transform(targets), label=\"target\")\n",
    "    plt.plot(revert_transform(f_test_targets[:training_len]), label=\"trailing\")\n",
    "\n",
    "    plt.title(f\"{title}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    if savefig:\n",
    "        plt.savefig(f\"{img_folder}{ticker}_all_preds.jpg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running model on all stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_tickers = [\"^GSPC\", \"AAPL\", \"MSFT\", \"NKE\", \"JPM\" , \"JNJ\" ]\n",
    "# need to download data for btc-usd!\n",
    "\n",
    "daily_data = download_data(shorter_tickers, \"2018-05-02\", \"2022-05-01\")\n",
    "close_data = daily_data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_tickers = [\"JNJ\", \"^GSPC\"]\n",
    "\n",
    "ckpt_dir='w2v_sampling'\n",
    "\n",
    "for v in range(3):\n",
    "    for ticker in shorter_tickers:\n",
    "        prices_data = pd.read_csv(f\"data/{ticker}.csv\")\n",
    "        prices_data = prices_data['Adj Close'].values\n",
    "        \n",
    "        features = create_features(prices_data)\n",
    "\n",
    "        train_features, val_features, test_features = split_data(features)\n",
    "        f_train_values, f_val_values, f_test_values, f_train_targets, f_val_targets, f_test_targets = preprocess_data(train_features, val_features, test_features)\n",
    "        \n",
    "        training_len = 60\n",
    "        forecast_len = 30\n",
    "\n",
    "        batch_size = 64\n",
    "\n",
    "        gen = torch.Generator()\n",
    "        gen.manual_seed(1233)\n",
    "\n",
    "        train_dataset = FeaturesDataset(f_train_values, f_train_targets, params['training_len'], forecast_len)\n",
    "        val_dataset = FeaturesDataset(f_val_values, f_val_targets, params['training_len'], forecast_len)\n",
    "        test_dataset = FeaturesDataset(f_test_values, f_test_targets, params['training_len'], forecast_len)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8, worker_init_fn=seed_worker, generator=gen)\n",
    "        val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        train_loader_unshuffled = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        \n",
    "        global train_output_img_dir\n",
    "        \n",
    "        img_dir = f\"train_output_imgs/transformer_n_step/{ckpt_dir}/{ticker}/\"\n",
    "        train_output_img_dir = img_dir\n",
    "        print(train_output_img_dir)\n",
    "\n",
    "        trainer, stock_model = train(ticker, version_name=f\"{ticker}_{v}\", model_name=f\"{ticker}_{v }\", ckpt_dir=ckpt_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"JPM\"\n",
    "\n",
    "prices_data = close_data[ticker].values\n",
    "# prices_data = pd.read_csv(f\"data/{ticker}.csv\")\n",
    "# prices_data = prices_data['Adj Close'].values\n",
    "features = create_features( prices_data = close_data[ticker].values)\n",
    "train_features, val_features, test_features = split_data(features)\n",
    "f_train_values, f_val_values, f_test_values, f_train_targets, f_val_targets, f_test_targets = preprocess_data(train_features, val_features, test_features)\n",
    "test_dataset = FeaturesDataset(f_test_values, f_test_targets, params['val_len'], forecast_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir=log_dir,\n",
    "    ### TODO: change version when reruun\n",
    "    version=f'test'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"valid_loss_epoch\",\n",
    "    mode=\"min\",\n",
    "    ### TODO: change dir path when rerun\n",
    "    dirpath=f\"test\",\n",
    "    filename=\"{epoch}-{valid_loss_epoch:.4f}\",\n",
    "    save_last= True,\n",
    "    save_top_k=2\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"valid_loss_epoch\",\n",
    "    mode=\"min\",\n",
    "    patience=100\n",
    ")\n",
    "\n",
    "metrics = {\"loss\": \"ptl/val_loss\"}\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    gpus=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    log_every_n_steps=7,\n",
    ")\n",
    "\n",
    "stock_model = TransformerTrainer(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "savefig=False\n",
    "ckpt_dir = 'w2v_sampling'\n",
    "stock_model = TransformerTrainer(params)\n",
    "ckpt_path = 'transformer_n_step_ahead_models/w2v_sampling/final_models/w2v_sampling_jpm.ckpt'\n",
    "all_preds = forecast(stock_model, trainer, ckpt_path, test_loader, 0)\n",
    "\n",
    "targets = f_test_targets[training_len:training_len+forecast_len] \n",
    "eval_res = evaluate(all_preds, targets)\n",
    "\n",
    "img_folder = f\"output_imgs/transformer_n_step/{ckpt_dir}/{ticker}_1/\"\n",
    "fig_title = f\"30-step ahead predictions with encoder-decoder architecture for {ticker}\"\n",
    "gen_fig(all_preds, eval_res, targets, img_folder, fig_title, savefig=savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2544b2e21dd89a55a8a8d54030eae89442a3bbda06d479011dbdd02f68dd50c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl_cw_pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
