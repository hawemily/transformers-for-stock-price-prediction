{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        input_dim, hidden_dim, dropout = config[\"input_dim\"], config[\"hidden_dim\"], config[\"dropout\"] \n",
    "        num_layers, output_dim = config[\"num_layers\"], config[\"output_dim\"]\n",
    "        seq_len = config[\"forecast_len\"]\n",
    "        training_len = config[\"training_len\"]\n",
    "\n",
    "        self.forecast_len = seq_len\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # input shape: [batch * seq_len * d_model]\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        #output layer\n",
    "        self.linear = nn.Linear(hidden_dim * training_len, seq_len)\n",
    "\n",
    "        self._device = config[\"device\"]\n",
    "        self.T = config[\"bptt\"]\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(self._device)\n",
    "        #initialise cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(self._device)\n",
    "        \n",
    "        out, (hi, ci) = self.lstm(x, (h0.detach(), c0.detach())) \n",
    "        \n",
    "        out = self.linear(out.contiguous().view(len(x), -1))\n",
    " \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "params = dict(\n",
    "    input_dim = 1,\n",
    "    hidden_dim = 64,\n",
    "    training_len = 60,\n",
    "    forecast_len = 30, \n",
    "    val_len = 60,\n",
    "    dropout = 0.1,\n",
    "    num_layers = 2,\n",
    "    output_dim = 1,\n",
    "    lr= 1e-3,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def get_prediction(t):\n",
    "    return [arr.view(-1) for arr in t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_img_dir = f\"train_output_imgs/lstm/^GSPC/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTrainer(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = LSTM_Model(config)\n",
    "        self.lr = config[\"lr\"]\n",
    "        self.training_len = config[\"training_len\"]\n",
    "        self.forecast_len = config[\"forecast_len\"]\n",
    "\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def calc_pearson_coeff(self, y_pred, y):\n",
    "\n",
    "        predicted = y_pred\n",
    "        targets = y\n",
    "        vy_pred = predicted - torch.mean(predicted)\n",
    "        vy = targets - torch.mean(targets)\n",
    "        denom = torch.sum(vy_pred ** 2) * torch.sum(vy ** 2)\n",
    "\n",
    "        corr = torch.sum(vy_pred * vy) / torch.sqrt(denom)\n",
    "\n",
    "        return corr\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, targets = batch\n",
    "        all_preds = [] \n",
    "\n",
    "        all_preds = self.model(src)\n",
    "            \n",
    "        y_hat = all_preds\n",
    "        y = targets.squeeze(-1) \n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        pearson_coeff = self.calc_pearson_coeff(y_hat, y)\n",
    "\n",
    "        self.log_dict({\"train_loss\":loss, \"train_pearson_coeff\":pearson_coeff}, prog_bar=True, on_epoch=True, on_step=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack(\n",
    "            [x[\"loss\"].detach() for x in outputs]).mean()\n",
    "        \n",
    "        self.log_dict({\"train_loss_epoch\": avg_loss, \"step\":self.current_epoch})\n",
    "\n",
    "        if self.current_epoch % 5 == 0:\n",
    "            self.print_pred(train_output_img_dir+\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        src, targets = batch\n",
    "        all_preds = []\n",
    "\n",
    "        all_preds = self.model(src)\n",
    "            \n",
    "        y_hat = all_preds\n",
    "        y = targets.squeeze(-1)\n",
    "\n",
    "        loss = self.criterion(y, y_hat)\n",
    "\n",
    "        pearson_coeff = self.calc_pearson_coeff(y_hat, y)\n",
    "\n",
    "        self.log_dict({\"val_loss\":loss, \"train_pearson_coeff\":pearson_coeff}, prog_bar=True, on_epoch=True, on_step=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def print_pred(self, file_prefix):\n",
    "        with torch.no_grad():\n",
    "            all_preds = []\n",
    "            init_train_data = []\n",
    "            all_targets = []\n",
    "\n",
    "            for step, trng_data in enumerate(train_loader_unshuffled):\n",
    "                if step == 2:\n",
    "                    break\n",
    "\n",
    "                src, targets = trng_data\n",
    "            \n",
    "                all_targets.append(targets.detach().cpu())\n",
    "\n",
    "                if step == 0:\n",
    "                    init_train_data = src[0, :, 0].reshape(-1)\n",
    "                \n",
    "                \n",
    "                preds = self(trng_data)\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "\n",
    "\n",
    "            all_preds = np.array(flatten(get_prediction(all_preds)))\n",
    "            all_targets = np.array(flatten(get_prediction(all_targets)))\n",
    "\n",
    "            #inverse transform\n",
    "\n",
    "            init_train_data = features_scaler.inverse_transform(init_train_data.reshape(-1, 1)).reshape(-1)\n",
    "            all_preds = features_scaler.inverse_transform(all_preds.reshape(-1, 1)).reshape(-1)\n",
    "            all_targets = features_scaler.inverse_transform(all_targets.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "            end_plot_idx = self.training_len + len(all_preds)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(init_train_data, label='trailing')\n",
    "            plt.plot(np.arange(self.training_len, end_plot_idx), all_preds, label=\"predicted\")\n",
    "            plt.plot(np.arange(self.training_len, end_plot_idx), all_targets, label=\"actual\")\n",
    "            plt.title(f\"Validation prediction for epoch {self.current_epoch}\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "\n",
    "            if not os.path.exists(file_prefix):\n",
    "                os.makedirs(file_prefix)\n",
    "\n",
    "            plt.savefig(f\"{file_prefix}/First_128_preds_Epoch_{self.current_epoch}.jpg\", bbox_inches=\"tight\")\n",
    "            \n",
    "            plt.close()\n",
    "\n",
    "             \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack(\n",
    "            [x['loss'].detach() for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"ptl/val_loss\", avg_loss)\n",
    "        \n",
    "        self.log_dict({\"valid_loss_epoch\": avg_loss, \"step\":self.current_epoch})\n",
    "\n",
    "        # if self.current_epoch % 5 == 0:\n",
    "        #     self.print_pred(train_output_img_dir+\"val\")\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        src, targets = x\n",
    "        all_preds = []\n",
    "\n",
    "        src = src.cuda()\n",
    "\n",
    "        all_preds = self.model(src)\n",
    "            \n",
    "        return all_preds\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureTargetSet = namedtuple('FeatureTargetSet', ['train_features', 'target_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, features, targets, training_len, forecast_len):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.training_len = training_len\n",
    "        self.forecast_len = forecast_len\n",
    "        self.feature_len = len(features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.feature_len - self.training_len - self.forecast_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        end_trng_idx = idx + self.training_len\n",
    "        end_target_idx = end_trng_idx + self.forecast_len\n",
    "\n",
    "        train_features = torch.as_tensor(self.features[idx:end_trng_idx], dtype=torch.float32)   \n",
    "        targets = torch.as_tensor(self.targets[end_trng_idx:end_target_idx], dtype=torch.float32)  \n",
    "        return FeatureTargetSet(train_features=train_features, target_values=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get prices data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(codes, start_date, end_date):\n",
    "    data = yf.download(codes, start_date, end_date)\n",
    "\n",
    "    if len(codes) == 1:\n",
    "        data.columns = [data.columns, codes*len(data.columns)]\n",
    "\n",
    "    return data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"^GSPC\", \"AAPL\", \"MSFT\", \"NKE\", \"JPM\", \"JNJ\", \"BTC-USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = download_data(tickers, \"2018-05-01\", \"2022-05-01\")\n",
    "close_data = daily_data[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_data = close_data['MSFT'].values\n",
    "prices_data = prices_data.reshape(-1)\n",
    "\n",
    "plt.plot(prices_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"MSFT\"\n",
    "features = close_data[ticker].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features):\n",
    "    train_idx = int(features.shape[0]*0.6)\n",
    "    val_idx = int(features.shape[0] * 0.2)\n",
    "    train_features = features[:train_idx]\n",
    "    val_features = features[train_idx:train_idx + val_idx]\n",
    "    test_features = features[train_idx + val_idx:]\n",
    "\n",
    "    return train_features, val_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, test_features = split_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = MinMaxScaler()\n",
    "features_scaler.fit(train_features.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_features, val_features, test_features):\n",
    "\n",
    "    features_scaler.fit(train_features.reshape(-1, 1))\n",
    "    \n",
    "    f_train_values = features_scaler.transform(train_features.reshape(-1, 1))\n",
    "    f_val_values = features_scaler.transform(val_features.reshape(-1, 1))\n",
    "    f_test_values = features_scaler.transform(test_features.reshape(-1, 1))\n",
    "\n",
    "    return f_train_values, f_val_values, f_test_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train_values, f_val_values, f_test_values = preprocess_data(train_features, val_features, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    input_dim = 1,\n",
    "    hidden_dim = 64,\n",
    "    training_len = 60,\n",
    "    forecast_len = 30,\n",
    "    val_len =60,\n",
    "    dropout = 0.1,\n",
    "    num_layers = 2\n",
    "    output_dim = 1,\n",
    "    lr= 1e-3,\n",
    "    device=device,\n",
    "    bptt = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_len = params['training_len']\n",
    "forecast_len = params['forecast_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = FeatureDataset(f_train_values, f_train_values, params['training_len'], forecast_len)\n",
    "val_dataset = FeatureDataset(f_val_values, f_val_values, params['val_len'], forecast_len)\n",
    "test_dataset = FeatureDataset(f_test_values, f_test_values, params['val_len'], forecast_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "train_loader_unshuffled = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = next(iter(train_loader))\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"lstm_logs\"\n",
    "model_dir = \"lstm_models\"\n",
    "\n",
    "device = (\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "\n",
    "def train(ticker, version_name = \"\", model_name=\"\", ckpt_dir = \"w2v\"):\n",
    "\n",
    "    if version_name == \"\":\n",
    "        version_name = ticker\n",
    "    \n",
    "    if model_name == \"\":\n",
    "        model_name = ticker\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "        ### TODO: change version when reruun\n",
    "        version=f'{version_name}_{ckpt_dir}'\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"valid_loss_epoch\",\n",
    "        mode=\"min\",\n",
    "        ### TODO: change dir path when rerun\n",
    "        dirpath=f\"{model_dir}/{ckpt_dir}/{ticker}\",\n",
    "        filename=\"{epoch}-{valid_loss_epoch:.4f}\",\n",
    "        save_last= True,\n",
    "        save_top_k=2\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"valid_loss_epoch\",\n",
    "        mode=\"min\",\n",
    "        patience=30\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        log_every_n_steps=9,\n",
    "        # deterministic=True\n",
    "    )\n",
    "\n",
    "    stock_model = LSTMTrainer(params)\n",
    "\n",
    "    trainer.fit(stock_model, train_loader, val_loader)\n",
    "\n",
    "    return trainer, stock_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, stock_model = train(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(y_true, y_pred):\n",
    "\n",
    "    rmse = np.sqrt(np.mean((y_true-y_pred)**2))                   \n",
    "    return rmse\n",
    "\n",
    "def calculate_mape(y_true, y_pred): \n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)    \n",
    "    mape = np.mean(np.abs((y_true-y_pred) / y_true))*100    \n",
    "    return mape\n",
    "\n",
    "\n",
    "def calc_pearson_coeff(y_pred, y):\n",
    "    predicted = y_pred\n",
    "    targets = y\n",
    "    vy_pred = predicted - np.mean(predicted)\n",
    "    vy = targets - np.mean(targets)\n",
    "    denom = np.sum(vy_pred ** 2) * np.sum(vy ** 2)\n",
    "\n",
    "    corr = np.sum(vy_pred * vy) / np.sqrt(denom)\n",
    "\n",
    "    return corr\n",
    "\n",
    "def mse_loss(pred, target, reduction='sum'):\n",
    "    loss = np.sum(np.square(pred - target))\n",
    "    if reduction == \"sum\":\n",
    "        return loss\n",
    "    else:\n",
    "        return loss / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_value(preds):\n",
    "    return [x.cpu().detach().numpy() for x in preds]\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return np.concatenate(preds, axis=0)\n",
    "\n",
    "def revert_transform(values):\n",
    "    return features_scaler.inverse_transform(values.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "def forecast(stock_model, trainer, ckpt_path, test_loader):\n",
    "    with torch.no_grad():\n",
    "        preds = trainer.predict(dataloaders=test_loader, model=stock_model, ckpt_path=ckpt_path)\n",
    "\n",
    "    all_preds = concat_preds(get_prediction_value(preds))\n",
    "\n",
    "    return all_preds\n",
    "\n",
    "def evaluate(pred, y):\n",
    "    pred = revert_transform(pred)\n",
    "    y = revert_transform(y)\n",
    "    \n",
    "    rmse = calculate_rmse(y, pred)\n",
    "    mse = rmse ** 2\n",
    "    mape = calculate_mape(y, pred)\n",
    "\n",
    "    r = calc_pearson_coeff(pred, y)\n",
    "\n",
    "    res = dict(\n",
    "        rmse = rmse,\n",
    "        mse =mse,\n",
    "        mape =mape,\n",
    "        r = r\n",
    "    )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'lstm_models/MSFT/epoch=11-valid_loss_epoch=0.0017.ckpt'\n",
    "all_preds = forecast(stock_model, trainer, ckpt_path, test_loader)\n",
    "eval_res = evaluate(all_preds, f_test_values[training_len:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = False\n",
    "img_folder =f\"output_imgs/lstm/{ticker}/\"\n",
    "\n",
    "def gen_fig(preds, eval_res, targets, img_folder, title, savefig=False):\n",
    "    with torch.no_grad():\n",
    "        if not os.path.exists(img_folder):\n",
    "            os.makedirs(img_folder)\n",
    "        \n",
    "        start_idx = training_len \n",
    "        end_idx = training_len + forecast_len \n",
    "        mse = eval_res[\"mse\"]\n",
    "\n",
    "        filename = f\"{img_folder}{ticker}_results.txt\" \n",
    "        if savefig:\n",
    "            if os.path.exists(filename):\n",
    "                f = open(filename, \"a\")\n",
    "                f.write(\"\\n\")\n",
    "            else:\n",
    "                f = open(filename, \"x\")\n",
    "\n",
    "        for metric in eval_res.keys():\n",
    "            print(f\"Metric {metric}: {eval_res[metric]}\")\n",
    "            if savefig:\n",
    "                f.write(f\"Metric {metric}: {eval_res[metric]}\\n\")\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        range_start_idx = training_len\n",
    "        range_end_idx = training_len + len(preds)\n",
    "        # predictions_flattened = np.array(all_preds)\n",
    "        plt.plot(list(range(range_start_idx, range_end_idx)), revert_transform(preds), label=\"predicted\")\n",
    "        plt.plot(list(range(range_start_idx, range_end_idx)), revert_transform(targets), label=\"target\")\n",
    "        plt.plot(revert_transform(f_test_values[:start_idx]), label=\"trailing\")\n",
    "        plt.title(f\"{title}\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        if savefig:\n",
    "            plt.savefig(f\"{img_folder}_all_preds.jpg\", bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models on all stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"^GSPC\", \"AAPL\", \"MSFT\", \"NKE\", \"JPM\", \"JNJ\"]\n",
    "\n",
    "daily_data = download_data(tickers, \"2018-05-02\", \"2022-05-01\")\n",
    "prices_data = daily_data[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_test = [\"^GSPC\", \"AAPL\", \"NKE\", \"JPM\", \"JNJ\"]\n",
    "\n",
    "ckpt_dir = \"lstm_n_step\"\n",
    "\n",
    "for ticker in ticker_test:\n",
    "        # print(prices_data)\n",
    "        features = prices_data[ticker].values\n",
    "\n",
    "        train_features, val_features, test_features = split_data(features)\n",
    "        f_train_values, f_val_values, f_test_values = preprocess_data(train_features, val_features, test_features)\n",
    "        \n",
    "        training_len = 60\n",
    "        forecast_len = 30\n",
    "\n",
    "        batch_size = 64\n",
    "\n",
    "        train_dataset = FeatureDataset(f_train_values, f_train_values, params['training_len'], forecast_len)\n",
    "        val_dataset = FeatureDataset(f_val_values, f_val_values, params['val_len'], forecast_len)\n",
    "        test_dataset = FeatureDataset(f_test_values, f_test_values, params['val_len'], forecast_len)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8)\n",
    "        val_loader = DataLoader(val_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        train_loader_unshuffled = DataLoader(train_dataset, batch_size, shuffle=False, num_workers=8)\n",
    "        \n",
    "        src, target = next(iter(train_loader))\n",
    "        print(src.shape)\n",
    "        print(target.shape)\n",
    "        \n",
    "        global train_output_img_dir\n",
    "        train_output_img_dir = f\"train_output_imgs/{ckpt_dir}/{ticker}/\"\n",
    "        \n",
    "        trainer, stock_model = train(ticker, version_name=f\"{ticker}\", model_name=f\"{ticker}\", ckpt_dir=ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"^GSPC\", \"AAPL\", \"MSFT\", \"NKE\", \"JPM\", \"JNJ\"]\n",
    "\n",
    "daily_data = download_data(tickers, \"2018-05-02\", \"2022-05-01\")\n",
    "prices_data = daily_data[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "\n",
    "features = prices_data[ticker].values\n",
    "\n",
    "train_features, val_features, test_features = split_data(features)\n",
    "f_train_values, f_val_values, f_test_values = preprocess_data(train_features, val_features, test_features)\n",
    "test_dataset = FeatureDataset(f_test_values, f_test_values, params['val_len'], forecast_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = f\"1-step ahead price prediction for {ticker}\"\n",
    "\n",
    "savefig = True\n",
    "stock_model = LSTMTrainer(params)\n",
    "ckpt_path = 'lstm_models/lstm_n_step/AAPL/epoch=5-valid_loss_epoch=0.0230.ckpt'\n",
    "all_preds = forecast(stock_model, trainer, ckpt_path, test_loader)\n",
    "eval_res = evaluate(all_preds[0], f_test_values[training_len:training_len + forecast_len])\n",
    "targets = f_test_values[training_len:training_len + forecast_len]\n",
    "img_folder = f\"output_imgs/{ckpt_dir}/{ticker}/\"\n",
    "fig_title = f\"30 step ahead prediction with prices for {ticker}\"\n",
    "gen_fig(all_preds[0], eval_res, targets, img_folder, fig_title, savefig=savefig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2544b2e21dd89a55a8a8d54030eae89442a3bbda06d479011dbdd02f68dd50c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl_cw_pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
